{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b9dd7e0",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.vectorstores import Chroma,FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08b99147",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "loader = DirectoryLoader('.', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59ecd754",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d6ed02d",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "# Embed and store the texts\n",
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "persist_directory = 'db'\n",
    "\n",
    "## here we are using OpenAI embeddings but in future we will swap out to local embeddings\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=texts, \n",
    "                                 embedding=embedding,\n",
    "                                 persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2c3326f",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# persiste the db to disk\n",
    "vectordb.persist()\n",
    "vectordb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26773589",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "vectordb = Chroma(persist_directory=persist_directory, \n",
    "                  embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f7f1111",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb35a260",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c88eed3d",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "# create the chain to answer questions \n",
    "qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(), \n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=retriever, \n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d05513ed",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# if os.path.exists(\"exl_jd.pkl\"):\n",
    "#     with open(\"exl_jd.pkl\", 'rb') as f:\n",
    "#         vectordb = pickle.load(f) \n",
    "#         print(\"Reading from disk\")\n",
    "        \n",
    "# else:\n",
    "#     #vectordb = Chroma.from_documents(texts,embedding=embedding)    \n",
    "#     vectordb=FAISS.from_documents(texts,embedding=embedding)    \n",
    "#     with open(\"exl_jd.pkl\",'wb') as f:\n",
    "#         pickle.dump(vectordb,f)\n",
    "#         print(\"computing embedinegs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af95ec70",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AT&T is offering a low price with eligible trade-in.\n",
      "\n",
      "\n",
      "Sources:\n",
      "att.txt\n",
      "att.txt\n",
      "att.txt\n",
      "verizon.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"verizon or att offering the low price?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "326bcdac",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AT&T is offering a trade in and save $1000 policy for new lines, and a trade in and save $830 policy for upgrades. Verizon does not appear to be offering any trade in policies.\n",
      "\n",
      "\n",
      "Sources:\n",
      "att.txt\n",
      "att.txt\n",
      "verizon.txt\n",
      "verizon.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"verizon or att offering the best trade in policy?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "55b36d95",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You can get the product with free 2 day shipping with a new line, free Express Pickup, or select a store. The product is sold by AT&T.\n",
      "\n",
      "\n",
      "Sources:\n",
      "att.txt\n",
      "att.txt\n",
      "verizon.txt\n",
      "att.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"what is the product availabelity to deliver the product and which seller\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cd621a",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "query = \"what is the product availabelity to deliver the product from the verizon\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
